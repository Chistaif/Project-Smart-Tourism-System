import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()

# Cáº¥u hÃ¬nh API
GENAI_API_KEY = os.environ.get('GEMINI_API_KEY')
if GENAI_API_KEY:
    genai.configure(api_key=GENAI_API_KEY)

# --- Cáº¤U HÃŒNH NHÃ‚N Váº¬T (SYSTEM PROMPT) ---
# ÄÃ¢y lÃ  bÃ­ quyáº¿t Ä‘á»ƒ AI viáº¿t hay!
MARKETING_SYSTEM_INSTRUCTION = """
Báº¡n lÃ  má»™t ChuyÃªn gia Content Marketing vÃ  HÆ°á»›ng dáº«n viÃªn du lá»‹ch Viá»‡t Nam áº£o cá»§a há»‡ thá»‘ng "Smart Tourism".
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ :
1. TrÃ² chuyá»‡n vá»›i khÃ¡ch hÃ ng vá»›i giá»ng vÄƒn: ThÃ¢n thiá»‡n, hÃ o há»©ng, chuyÃªn nghiá»‡p vÃ  lÃ´i cuá»‘n.
2. Khi mÃ´ táº£ Ä‘á»‹a Ä‘iá»ƒm, Äá»ªNG liá»‡t kÃª khÃ´ khan. HÃ£y dÃ¹ng tá»« ngá»¯ gá»£i hÃ¬nh, gá»£i cáº£m xÃºc (vÃ­ dá»¥: "Ä‘áº¹p nhÆ° tranh váº½", "thiÃªn Ä‘Æ°á»ng háº¡ giá»›i", "chá»¯a lÃ nh tÃ¢m há»“n").
3. LuÃ´n gá»£i Ã½ thÃªm cÃ¡c hoáº¡t Ä‘á»™ng thÃº vá»‹ Ä‘á»ƒ kÃ­ch thÃ­ch khÃ¡ch hÃ ng Ä‘i du lá»‹ch.
4. Sá»­ dá»¥ng cÃ¡c emoji ğŸŒ¿âœ¨ğŸ“¸ phÃ¹ há»£p Ä‘á»ƒ bÃ i viáº¿t sinh Ä‘á»™ng.
5. Tuyá»‡t Ä‘á»‘i khÃ´ng bá»‹a Ä‘áº·t thÃ´ng tin sai lá»‡ch vá» lá»‹ch sá»­/vÄƒn hÃ³a.
"""

def chat_with_tour_guide(user_message, context_data=None, chat_history=[]):
    """
    HÃ m chatbot tÆ° váº¥n trá»±c tiáº¿p
    :param user_message: CÃ¢u há»i cá»§a user
    :param context_data: Dá»¯ liá»‡u vá» cÃ¡c Ä‘á»‹a Ä‘iá»ƒm hiá»‡n cÃ³ (Ä‘á»ƒ AI biáº¿t mÃ  tÆ° váº¥n)
    :param chat_history: List lá»‹ch sá»­ chat tá»« Frontend gá»­i lÃªn 
                         Format: [{'role': 'user', 'parts': ['text']}, {'role': 'model', 'parts': ['text']}]
    """
    if not GENAI_API_KEY:
        return "Há»‡ thá»‘ng Ä‘ang báº£o trÃ¬."

    model = genai.GenerativeModel(
        'gemini-2.5-flash',
        system_instruction=MARKETING_SYSTEM_INSTRUCTION
    )

    # 1. Táº¡o phiÃªn chat vá»›i lá»‹ch sá»­ cÅ© (náº¿u cÃ³)
    formatted_history = []
    for msg in chat_history:
        # Chá»‰ láº¥y cÃ¡c tin nháº¯n há»£p lá»‡ Ä‘á»ƒ trÃ¡nh lá»—i API
        if msg.get('role') in ['user', 'model'] and msg.get('parts'):
            formatted_history.append({
                "role": msg['role'],
                "parts": msg['parts']
            })

    chat_session = model.start_chat(history=formatted_history)

    # 2. Nhá»“i Context vÃ o cÃ¢u há»i hiá»‡n táº¡i (ká»¹ thuáº­t Prompt Engineering)
    # Thay vÃ¬ gá»­i context vÃ o system_instruction (tÄ©nh), ta gá»­i kÃ¨m vÃ o message má»›i nháº¥t
    # Ä‘á»ƒ AI luÃ´n Æ°u tiÃªn dá»¯ liá»‡u thá»±c táº¿.
    prompt = user_message
    if context_data:
        prompt = f"""
        [ThÃ´ng tin há»‡ thá»‘ng cung cáº¥p: {context_data}]
        CÃ¢u há»i cá»§a khÃ¡ch: {user_message}
        YÃªu cáº§u: tráº£ lá»i ngáº¯n gá»n, xÃºc tÃ­ch nhÆ°ng pháº£i cuá»‘n hÃºt.
        """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"Error calling Google AI API: {str(e)}")  # Debug log
        return "Xin lá»—i, mÃ¬nh Ä‘ang suy nghÄ© chÃºt, báº¡n há»i láº¡i sau nhÃ©!"


def generate_caption(attraction_name, features=None):
    """
    HÃ m chuyÃªn dÃ¹ng Ä‘á»ƒ viáº¿t caption/mÃ´ táº£ ngáº¯n cho blog
    """
    if not GENAI_API_KEY:
        return "Há»‡ thá»‘ng Ä‘ang báº£o trÃ¬."

    model = genai.GenerativeModel(
        'gemini-2.5-flash',
        system_instruction=MARKETING_SYSTEM_INSTRUCTION
    )

    features_str = f", cÃ³ cÃ¡c Ä‘áº·c Ä‘iá»ƒm: {features}" if features else ""
    
    prompt = f"""
    HÃ£y viáº¿t má»™t Ä‘oáº¡n vÄƒn ngáº¯n (khoáº£ng 3-4 cÃ¢u) tháº­t háº¥p dáº«n Ä‘á»ƒ giá»›i thiá»‡u vá»: {attraction_name}{features_str}.
    Má»¥c tiÃªu: ÄÄƒng lÃªn máº¡ng xÃ£ há»™i Ä‘á»ƒ thu hÃºt giá»›i tráº» Ä‘i du lá»‹ch ngay láº­p tá»©c.
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Lá»—i AI: {str(e)}"


def generate_tour_description(tour_attracions):
    """
    HÃ m chuyÃªn dÃ¹ng ná»™i bá»™ Ä‘á»ƒ sinh ra tour name háº¥p dáº«n
    """
    if not GENAI_API_KEY:
        return "Há»‡ thá»‘ng Ä‘ang báº£o trÃ¬."

    model = genai.GenerativeModel(
        'gemini-2.5-flash',
        system_instruction=MARKETING_SYSTEM_INSTRUCTION
    )

    attraction_names = [attraction.name for attraction in tour_attracions]
    
    prompt = f"""
    HÃ£y táº¡o cho tÃ´i má»™t cÃ¡i tÃªn tháº­t háº¥p dáº«n vÃ  cuá»‘n hÃºt ngÆ°á»i dÃ¹ng vá» tour Ä‘i Ä‘áº¿n cÃ¡c Ä‘iá»ƒm {attraction_names}
    """

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Lá»—i AI: {str(e)}"